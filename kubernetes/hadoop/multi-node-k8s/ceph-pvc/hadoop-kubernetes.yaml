########################
# NAMENODE
########################    
apiVersion: v1
kind: Service
metadata:
  name: namenode
  namespace: cephfs
  labels:
    app: hadoop
spec:
  ports:
    - port: 8020
      targetPort : 8020
      name: namenode
    - port: 9870
      targetPort: 9870
      name: ui
  selector:
    app: hadoop
    tier: namenode
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: namenode
  namespace: cephfs
  labels:
    app: hadoop
spec:
  selector:
    matchLabels:
      app: hadoop
  serviceName: namenode
  replicas: 1
  template:
    metadata:
      labels:
        app: hadoop
        tier: namenode  
    spec:
      containers:
      - name: namenode
        image: dmitryzagr/hadoop-namenode:hadoop3.0.1-java8
        env:
        envFrom:
          - configMapRef:
              name: hadoop-env
        ports:
        - containerPort: 8020
          name: namenode
        - containerPort: 9870
          hostPort: 9870
          name: ui
        volumeMounts:
        - name: namenode-data
          mountPath: /hadoop/dfs/name
        - name: namenode-archives
          mountPath: /root/hadoop_data
      volumes:
      - name: namenode-archives
        emptyDir: {}
      nodeSelector:
        server-type: namenode
  volumeClaimTemplates:
  - metadata:
      name: namenode-data
    spec:
      storageClassName: cephfs
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
########################
# DATANODE
########################
apiVersion: v1
kind: Service
metadata:
  name: datanode
  namespace: cephfs
  labels:
    app: hadoop
spec:
  ports:
    - port: 50010
      targetPort: 50010
  selector:
    app: hadoop
    tier: datanode
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: datanode
  namespace: cephfs
  labels:
    app: hadoop
spec:
  selector:
    matchLabels:
      app: hadoop
  serviceName: datanode
  replicas: 5
  template:
    metadata:
      labels:
        app: hadoop
        tier: datanode  
    spec:
      containers:
      - name: datanode
        image: dmitryzagr/hadoop-datanode:hadoop3.0.1-java8
        env:
        envFrom:
          - configMapRef:
              name: hadoop-env
        ports:
        - containerPort: 50010
          name: datanode
        volumeMounts:
        - name: datanode-data
          mountPath: /hadoop/dfs/data
        - name: datanode-archives
          mountPath: /root/hadoop_data
      volumes:
      - name: datanode-archives
        emptyDir: {}
      nodeSelector:
        server-type: datanode
  volumeClaimTemplates:
  - metadata:
      name: datanode-data
    spec:
      storageClassName: cephfs
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
########################
# SPARK-MASTER
########################
apiVersion: v1
kind: Service
metadata:
  name: spark-master
  namespace: cephfs
  labels:
    app: hadoop
spec:
  ports:
    - port: 7077
      name: spark-master
    - port: 8080
      name: spark-master-ui
      targetPort: 8080
  selector:
    app: hadoop
    tier: spark-master
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: spark-master
  namespace: cephfs
  labels:
    app: hadoop
spec:
  selector:
    matchLabels:
      app: hadoop
  serviceName: spark-master
  template:
    metadata:
      labels:
        app: hadoop
        tier: spark-master 
    spec:
      containers:
      - name: spark-master
        image: dmitryzagr/spark-master:2.2.0-hadoop3.0.0-java8
        env:
        envFrom:
          - configMapRef:
              name: hadoop-env
        ports:
        - containerPort: 7077
          name: spark-master
        - containerPort: 8080
          name: spark-master-ui
      nodeSelector:
        server-type: namenode
---
########################
# SPARK-WORKER
########################
apiVersion: v1
kind: Service
metadata:
  name: spark-worker
  namespace: cephfs
  labels:
    app: hadoop
spec:
  ports:
    - port: 41667
      name: spark-worker
  selector:
    app: hadoop
    tier: spark-worker
  clusterIP: None
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-worker
  namespace: cephfs
  labels:
    app: hadoop
spec:
  selector:
    matchLabels:
      app: hadoop
      tier: spark-worker
  replicas: 5
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: hadoop
        tier: spark-worker
    spec:
      containers:
      - image: dmitryzagr/spark-worker:2.2.0-hadoop3.0.0-java8
        name: spark-worker
        env:
        envFrom:
          - configMapRef:
              name: hadoop-env
        ports:
        - containerPort: 41667
          name: spark-worker
      nodeSelector:
        server-type: datanode
---
########################
# HIVE-SERVER
########################
apiVersion: v1
kind: Service
metadata:
  name: hive-server
  namespace: cephfs
  labels:
    app: hadoop
spec:
  ports:
    - port: 10000
      name: hive-server1
    - port: 10002
      name: hive-server2
  selector:
    app: hadoop
    tier: hive-server
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: hive-server
  namespace: cephfs
  labels:
    app: hadoop
spec:
  selector:
    matchLabels:
      app: hadoop
  serviceName: hive-server
  template:
    metadata:
      labels:
        app: hadoop
        tier: hive-server
    spec:
      containers:
      - name: hive-server
        image: dmitryzagr/hadoop-hive:2.3.2-hadoop3.0.1-java8
        env:
        envFrom:
          - configMapRef:
              name: hadoop-env
        env:
        - name: HIVE_CORE_CONF_javax_jdo_option_ConnectionURL
          value: "jdbc:postgresql://hive-metastore/metastore"
        ports:
        - containerPort: 10000
          name: hive-server1
        - containerPort: 10002
          name: hive-server2
      nodeSelector:
        server-type: namenode
---
########################
# HIVE-METASTORE
########################
apiVersion: v1
kind: Service
metadata:
  name: hive-metastore
  namespace: cephfs
  labels:
    app: hadoop
spec:
  ports:
    - port: 9083
      name: hive-metastore
  selector:
    app: hadoop
    tier: hive-metastore
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: hive-metastore
  namespace: cephfs
  labels:
    app: hadoop
spec:
  selector:
    matchLabels:
      app: hadoop
  serviceName: hive-metastore
  template:
    metadata:
      labels:
        app: hadoop
        tier: hive-metastore
    spec:
      containers:
      - image: dmitryzagr/hadoop-hive:2.3.2-hadoop3.0.1-java8
        name: hive-metastore
        command: ["/opt/hive/bin/hive"]
        args: ["--service", "metastore"]
        env:
        envFrom:
          - configMapRef:
              name: hadoop-env
        ports:
        - containerPort: 9083
          name: hive-metastore
      nodeSelector:
        server-type: namenode
---
############################
# HIVE-METASTORE-POSTGRESQL
############################    
apiVersion: v1
kind: Service
metadata:
  name: hive-postgresql
  namespace: cephfs
  labels:
    app: hadoop
spec:
  ports:
    - port: 5432
  selector:
    app: hadoop
    tier: hive-postgresql
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: hive-postgresql
  namespace: cephfs
  labels:
    app: hadoop
spec:
  selector:
    matchLabels:
      app: hadoop
  serviceName: hive-postgresql
  template:
    metadata:
      labels:
        app: hadoop
        tier: hive-postgresql
    spec:
      containers:
      - image: dmitryzagr/hive-metastore-postgresql:2.3.2
        name: hive-postgresql
        env:
        envFrom:
          - configMapRef:
              name: hadoop-env
        env:
        - name: POSTGRESQL_PASSWORD
          value: "keycloak"
        - name: POSTGRESQL_USER
          value: "keycloak"
        - name: POSTGRESQL_DATABASE
          value: "keycloak"
        ports:
        - containerPort: 5432
          name: hive-postgresql
        volumeMounts:
        - name: hive-postgresql-data
          mountPath: /var/lib/postgresql/data
      nodeSelector:
        server-type: namenode
  volumeClaimTemplates:
  - metadata:
      name: hive-postgresql-data
    spec:
      storageClassName: cephfs
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
########################
# ZEPPELIN
########################
apiVersion: v1
kind: Service
metadata:
  name: zeppelin-ui
  namespace: cephfs
  labels:
    app: hadoop
spec:
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
      name: zeppelin
  selector:
    app: hadoop
    tier: zeppelin-ui
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: zeppelin-ui
  namespace: cephfs
  labels:
    app: hadoop
spec:
  selector:
    matchLabels:
      app: hadoop
  serviceName: zeppelin-ui
  template:
    metadata:
      labels:
        app: hadoop
        tier: zeppelin-ui
    spec:
      containers:
      - image: dmitryzagr/zeppelin:0.8.0-SNAPSHOT-spark2.2.0-hadoop3.0.1
        name: zeppelin-ui
        env:
        envFrom:
          - configMapRef:
              name: hadoop-env
        env:
        - name: ZEPPELIN_LOG_DIR
          value: "/data-zeppelin/logs"
        - name: ZEPPELIN_NOTEBOOK_DIR
          value: "/data-zeppelin/notebook"
        - name: ZEPPELIN_SERVER_CONTEXT_PATH
          value: "/zeppelin"
        - name: ZEPPELIN_PORT
          value: "8080"
        - name: ZEPPELIN_WEBSOCKET_MAX_TEXT_MESSAGE_SIZE
          value: "10240000"
        ports:
        - containerPort: 8080
          name: zeppelin
        volumeMounts:
        - name: zeppelin-ui-data
          mountPath: /data-zeppelin
        - name: zeppelin-conf-shiro
          mountPath: /zeppelin/conf/shiro.ini
          subPath: shiro.ini
        - name: zeppelin-conf-interpreter
          mountPath: /zeppelin/conf/interpreter.json
          subPath: interpreter.json
        - name: zeppelin-conf-site
          mountPath: /zeppelin/conf/zeppelin-site.xml
          subPath: zeppelin-site.xml
      volumes:
      - name: zeppelin-conf-shiro
        secret:
          secretName: zeppelin-conf-shiro
      - name: zeppelin-conf-interpreter
        secret:
          secretName: zeppelin-conf-interpreter
      - name: zeppelin-conf-site
        secret:
          secretName: zeppelin-conf-site
      nodeSelector:
        server-type: namenode
  volumeClaimTemplates:
  - metadata:
      name: zeppelin-ui-data
    spec:
      storageClassName: cephfs
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
########################
# TRAEFIK
########################
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: hadoop-statefull-k8s
  namespace: cephfs
  annotations:
    kubernetes.io/ingress.class: traefik
    traefik.frontend.rule.type: PathPrefix
spec:
  rules:
  - http:
      paths:
      - path: /zeppelin
        backend:
          serviceName: zeppelin-ui
          servicePort: zeppelin
      - path: /
        backend:
          serviceName: spark-master
          servicePort: spark-master-ui
      - path: /auth
        backend:
          serviceName: keycloak
          servicePort: http
---
########################
# OPENLDAP
########################
apiVersion: v1
kind: Service
metadata:
  name: openldap
  namespace: cephfs
  labels:
    app: che
spec:
  ports:
    - port: 389
      targetPort: 389
      name: openldap
  selector:
    app: che
    tier: openldap
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: openldap
  namespace: cephfs
  labels:
    app: che
spec:
  selector:
    matchLabels:
      app: che
      tier: openldap
  serviceName: openldap
  template:
    metadata:
      labels:
        app: che
        tier: openldap
    spec:
      containers:
      - image: dmitryzagr/openldap:1.1.9
        name: openldap
        command: ["/container/service/docker-entrypoint.sh"]
        env:
        - name: LDAP_LOG_LEVEL
          value: "256"
        - name: LDAP_ORGANISATION
          value: "1C"
        - name: LDAP_DOMAIN
          value: "base.com"
        - name: LDAP_BASE_DN
          value: "dc=base,dc=com"
        - name: LDAP_ADMIN_PASSWORD
          value: "adminpassword"
        - name: LDAP_CONFIG_PASSWORD
          value: "config"
        - name: LDAP_READONLY_USER
          value: "false"
        - name: LDAP_RFC2307BIS_SCHEMA
          value: "false"
        - name: LDAP_BACKEND
          value: "hdb"
        - name: LDAP_TLS
          value: "true"
        - name: LDAP_TLS_CRT_FILENAME
          value: "ldap.crt"
        - name: LDAP_TLS_KEY_FILENAME
          value: "ldap.key"
        - name: LDAP_TLS_CA_CRT_FILENAME
          value: "ca.crt"
        - name: LDAP_TLS_ENFORCE
          value: "false"
        - name: LDAP_TLS_CIPHER_SUITE
          value: "SECURE256:-VERS-SSL3.0"
        - name: LDAP_TLS_PROTOCOL_MIN
          value: "3.1"
        - name: LDAP_TLS_VERIFY_CLIENT
          value: "demand"
        - name: LDAP_REPLICATION
          value: "false"
        - name: KEEP_EXISTING_CONFIG
          value: "false"
        - name: LDAP_REMOVE_CONFIG_AFTER_SETUP
          value: "true"
        - name: LDAP_SSL_HELPER_PREFIX
          value: "ldap"
        - name: LDAP_BACKUP_CONFIG_CRON_EXP
          value: "*/50 * * * *"
        - name: LDAP_BACKUP_DATA_CRON_EXP
          value: "*/50 * * * *"
        - name: LDAP_BACKUP_TTL
          value: "1"
        - name: ADD_DEFAULT_NODES_TIMEOUT
          value: "60"
        ports:
        - containerPort: 389
          name: openldap
        volumeMounts:
        - name: openldap-ldap-data
          mountPath: /var/lib/ldap
          subPath: openldap/ldap
        - name: openldap-ldap-data
          mountPath: /etc/ldap/slapd.d
          subPath: openldap/slapd.d
        - name: openldap-ldap-data
          mountPath: /container/service/slapd/assets/certs
          subPath: openldap/certs
        - name: openldap-ldap-data
          mountPath: /data/backup
          subPath: openldap/backup
      nodeSelector:
        server-type: namenode
  volumeClaimTemplates:
  - metadata:
      name: openldap-ldap-data
    spec:
      storageClassName: cephfs
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
########################
# KEYCLOAK
########################
apiVersion: v1
kind: Service
metadata:
  name: keycloak
  namespace: cephfs
  labels:
    app: che
spec:
  ports:
    - port: 8080
      targetPort: 8080
      name: http
  selector:
    app: che
    tier: keycloak
---
apiVersion: apps/v1beta2 # for versions before 1.8.0 use apps/v1beta1
kind: Deployment
metadata:
  name: keycloak
  namespace: cephfs
  labels:
    app: che
spec:
  selector:
    matchLabels:
      app: che
      tier: keycloak
  template:
    metadata:
      labels:
        app: che
        tier: keycloak
    spec:
      containers:
      - image: dmitryzagr/keycloak-openshift:3.4.0.Final
        name: keycloak
        command: ["start-keycloak.sh"]
        args: ["-Dkeycloak.migration.action=import", "-Dkeycloak.migration.provider=dir", "-Dkeycloak.migration.strategy=IGNORE_EXISTING", "-Dkeycloak.migration.dir=/opt/jboss/keycloak/realms/", "-Djboss.bind.address=0.0.0.0"]
        env:
        - name: POSTGRES_PORT_5432_TCP_ADDR
          value: "hive-postgresql"
        - name: POSTGRES_PORT_5432_TCP_PORT
          value: "5432"
        - name: POSTGRES_DATABASE
          value: "keycloak"
        - name: POSTGRES_USER
          value: "keycloak"
        - name: POSTGRES_PASSWORD
          value: "keycloak"
        - name: PROXY_ADDRESS_FORWARDING
          value: "true"
        - name: CHE_REDIRECT_URIS
          value: '"*"'
        - name: CHE_WEB_ORIGINS
          value: '"*"'
        - name: LDAP_BASE_DN
          value: "dc=base,dc=com"
        - name: LDAP_PASSWORD
          value: "adminpassword"
        ports:
        - containerPort: 8080
          name: http
      nodeSelector:
        server-type: namenode
---
